\documentclass[../main.tex]{subfiles}

\begin{document}
\chapter{Weyl Spinors \& Grassmann Calculus}
\label{app:chap:weyl_grassmann}


\chapter{Takagi Factorisation Algorithm}
\label{app:chap:takagi}
\section{Schur decomposition and singular-value decomposition}
Schur decomposition tells us that any (potentially complex) matrix \(A\) can be written as
\[
  A = U^\dagger \Delta U,
\]
where \(U\) is a unitary matrix, and \(\Delta\) is an upper triangular matrix.
It follows then that if \(A\) is a symmetric matrix (\(A^T = A\)), then
\[
  \pclosed{U^\dagger \Delta U} = \pclosed{U^\dagger \Delta U}^T = U^T \Delta^T U^\ast
\]

\section{Proof of Takagi Factorisation}
Here, I go through the proofs necessary for the procedure defined in \cref{susy:sec:takagi} to find the Takagi diagonalising matrix \(U\) s.t. for a complex, symmetric matrix \(A = U^T A U\).

\section{Proofs}
\paragraph{The Takagi vector.}
For any \(A \in M_{n}(\mathbb{C})\) such that \(AA^\ast\) only has real, non-negative eigenvalues, there exists a non-zero vector \(\vec{v} \in \mathbb{C}^n\) such that \(A \vec{v}^* = \sigma \vec{v}\), where \(\sigma\) is a real, non-negative number.\\
\emph{Proof.} Consider a vector \(\vec{x} \neq \vec{0} \in \mathbb{C}^n\) that is an eigenvector of \(AA^\ast\) with corresponding eigenvalue \(\lambda\).
There are two cases:
\begin{itemize}
  \item[(a)] \(A\vec{x}^*\) and \(\vec{x}\) are linearly dependent.
  \item[(b)] \(A\vec{x}^*\) and \(\vec{x}\) are linearly independent.
\end{itemize}
In case (a), we must have that \(A\vec{x}^* = \mu \vec{x}\) for some \(\mu \in \mathbb{C}\), since they are linearly dependent.
Then \(AA^\ast \vec{x} = A \mu^\ast \vec{x}^* = \abs{\mu}^2 \vec{x} \equiv \lambda \vec{x}\), which is non-negative by definition.\\
In case (b), the vector \(\vec{y} = A\vec{x}^* + \mu \vec{x}\) is non-zero for any \(\mu \in \mathbb{C}\), since \(A\vec{x}^*\) and \(\vec{x}\) are linearly independent.
Then we can choose \(\mu\) such that \(\abs{\mu}^2 = \lambda\) to get that \(A \vec{y}^* = A\pclosed{A^\ast \vec{x} + \mu^\ast \vec{x}^*} = \lambda\vec{x} + \mu^\ast A\vec{x^*} = \mu\mu^\ast \vec{x} + \mu^\ast A\vec{x}^* = \mu^\ast \pclosed{A \vec{x}^* + \mu \vec{x}} = \mu^\ast \vec{y}\).\\
As such, we can always find a vector \(\tilde{\vec{v}} \in \mathbb{C}^n\) such that \(A \tilde{\vec{v}}^* = \mu \tilde{\vec{v}}\) for some \(\mu \in \mathbb{C}^n\).
Furthermore, we can define a vector \(\vec{v} = \exp{i\theta} \tilde{\vec{v}}\) for a \(\theta \in \mathbb{R}\) to get \(A\vec{v}^* = A \pclosed{\exp{i\theta} \tilde{\vec{v}}}^\ast = \exp{-i\theta} A\tilde{\vec{v}}^* = \exp{-i\theta} \mu \tilde{\vec{v}} = \exp{-2i\theta} \mu \exp{i\theta} \tilde{\vec{v}} = \exp{-2i\theta} \mu \vec{v} \equiv \sigma \vec{v}\).
This allows us to choose the phase of \(\sigma = \exp{-2i\theta} \mu\) to be such that \(\sigma\) is real and non-negative.
\medskip

\paragraph{Eigenvalues of \(AA^\ast\) for symmetric \(A\).}
Given an \(N \by N\) complex matrix \(A\), the eigenvalues of \(AA^\ast\) are always real and non-negative.\\
\emph{Proof}.
Consider \(\vec{x} \neq \vec{0}\) an eigenvector of \(AA^\ast\) with corresponding eigenvalue \(\lambda\).
Then we must have that
\[\lambda \vec{x}^\dagger \vec{x} = \vec{x}^\dagger AA^\ast \vec{x} = \pclosed{A^\dagger \vec{x}}^\dagger \pclosed{A^\ast \vec{x}} = \pclosed{A^\ast \vec{x}}^\dagger \pclosed{A^\ast \vec{x}},\]
where we have used that \(A^\dagger = \pclosed{A^T}^\ast = A^\ast\).
This means that \(\lambda \geq 0\), since for any vector \(\vec{v} \in \mathbb{C}^n\) we have that \(\vec{v}^\dagger \vec{v} \geq 0\).
As this holds for all eigenvectors \(\vec{x}\) of \(AA^\ast\), all its eigenvalues must be non-negative.

\paragraph{Diagonalisation step of a symmetric matrix \(A\).}
For any symmetric matrix \(A \in M_n(\mathbb{C})\), there exist a unitary matrix \(V \in M_n(\mathbb{C})\) such that
\[V^\dagger A V^\ast = \begin{pmatrix} \sigma & \vec{0} \\ \vec{0} & A_2 \end{pmatrix},\]
where \(\sigma\) is a real, non-negative number and \(A_2 \in M_{n-1}(\mathbb{C})\) is also a symmetric matrix. \\
\emph{Proof.}
Consider a normalised Takagi vector \(\vec{v} \neq \vec{0}\) of \(A\) such that \(A\vec{v}^\ast = \sigma \vec{v}\) for some real, non-negative \(\sigma\) and \(\vec{v}^\dagger \vec{v} = 1\).
We can then complete an orthonormal basis for \(\mathbb{C}^n\) with unit vectors \(\vec{v}_i\) where \(i \in 1, \ldots, n\), where we define \(\vec{v}_1 \equiv \vec{v}\).
Defining a unitary matrix \(V = \bclosed{\vec{v}_1, \ldots, \vec{v}_{n}}\), the first column of the product
\[\pclosed{V^\dagger A V^\ast}_{i1} = \vec{v}_i^\dagger A \vec{v}^* = \vec{v}_i^\dagger \sigma \vec{v} = \sigma \delta_{i1},\]
where \(\delta_{ij}\) is the Kronecker delta symbol, and we have used the Takagi property of \(\vec{v}\) and the orthonormality of \(\vec{v}_i^\dagger \vec{v}_j\).
This means only the first component of the first column of \(V^\dagger A V^\ast\) is non-zero, and has value \(\sigma\).
Now since \(A\) is symmetric, we have that
\(\pclosed{V^\dagger A V^\ast}^T = V^\dagger A^T V^\ast = V^\dagger A V^\ast\)
must also be symmetric, and thus must have the form
\[V^\dagger A V^\ast = \begin{pmatrix} \sigma & \vec{0} \\ \vec{0} & A_2 \end{pmatrix},\]
for a symmetric \(A_2 \in M_{n-1}(\mathbb{C})\).


% \bibliography{references}{}
% \bibliographystyle{style/JHEP}


\end{document}
