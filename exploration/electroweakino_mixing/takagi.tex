\documentclass[english, notitlepage]{article}

\usepackage{overhead}
\usepackage[style=verbose]{biblatex}

\addbibresource{takagi.bib}

\title{Takagi Factorisation}
\author{Carl Martin Fevang}

\begin{document}
\maketitle

\begin{abstract}
    This document describes the diagonalisation procedure by Takagi for diagonalising symmetric, complex-valued matrices.
\end{abstract}

\section{Schur decomposition and singular-value decomposition}
    Schur decomposition tells us that any (potentially complex) matrix \(A\) can be written as
    \[
        A = U^\dagger \Delta U,
    \]
    where \(U\) is a unitary matrix, and \(\Delta\) is an upper triangular matrix.
    It follows then that if \(A\) as a symmetric matrix (\(A^T = A\)), then
    \[
        \pclosed{U^\dagger \Delta U} = \pclosed{U^\dagger \Delta U}^T = U^T \Delta^T U^\ast
    \]

\section{Takagi factorisation}
    Assume \(A = A^T\) is a symmetric, complex-valued, \(n \by n\) matrix.
    Takagi factorisation~\autocite{Horn} tells us that there exists a unitary matrix \(U\), and a real, non-negative diagonal matrix \(D\) such that
    \begin{equation}
        \label{eq:takagi}
        A = U^T D U.
    \end{equation}

    \subsection{Factorisation algorithm}
        The algorithm is will be based on finding vector \(\vec{v} \in  \mathbb{C}^n\) that satisfy \(A \vec{v}^* = \sigma \vec{v}\), for some real, positive \(\sigma\).
        This vector will be called a \emph{Takagi vector} for future reference.
        Existence of these vectors for any matrix \(A\) such that \(AA^\ast\) only has real, positive eigenvalues is detailed later.

        To find \(U\), I propose here an algorithm based on the proof for Takagi factorisation in~\autocite{Horn}.
        Given a Takagi vector \(\vec{v} \in \mathbb{C}^n\) of \(A\),\footnote{A proof that this can be found is detailed elsewhere.} and an orthonormal basis \(\cclosed{\vec{v}, \vec{v}_2, \ldots, \vec{v}_n}\) of \(\mathbb{C}^n\), it is possible to write \(A\) as
        \[
            A = V \begin{bmatrix}
                \sigma         & \boldsymbol{0} \\
                \boldsymbol{0} & A_2
            \end{bmatrix} V^T,
        \]
        where \(A_2\) is a symmetric \((n-1) \by (n-1)\) matrix and \(V\) is a unitary matrix with the aforementioned orthonormal basis as its columns.
        This process can be repeated with \(A_2\) and so on until you have
        \[
            A = V_1 \cdots V_{n} \begin{bmatrix}
                \sigma_1                                            & \multicolumn{2}{c}{\raisebox{-7pt}{\mbox{\Large 0}}}   \\
                                                                    & \ddots                                               & \\
                \multicolumn{2}{c}{\raisebox{7pt}{\mbox{\Large 0}}} & \sigma_n
            \end{bmatrix} V_{n}^T \cdots V_{1}^T,
        \]
        where
        \[
            V_p = \begin{bmatrix}
                \mathbb{I}_{(p-1) \by (p-1)} & \boldsymbol{0} \\
                \boldsymbol{0}               & \tilde{V}_p,
            \end{bmatrix}
        \]
        and \(\tilde{V}_p\) is the unitary matrix that makes a diagonalisation step on \(A_p\).
        Comparing to \cref{eq:takagi}, we find that
        \begin{subequations}
            \begin{align}
                U & = V_{n}^T \cdots V_{1}^T,                                  \\
                D & = \operatorname{diag}\pclosed{\sigma_1, \ldots, \sigma_n}.
            \end{align}
        \end{subequations}
        It is easy to show that \(U\) is unitary, as promised.
        Furthermore, by assumption, all the values \(\sigma_p\) are real and positive.
        Now the values on the diagonal of \(D\) can be permuted to any order using a permutation matrix \(P\), such that we get
        \[
            A = U_P^T D_P U_P,
        \]
        where \(U_P = P U\) and \(D_P = P D P^T\).
        \(U_P\) is still unitary, and \(D_P\) diagonal.



\section{Proofs}
    \paragraph{The Takagi vector.}
    For any \(A \in M_{n}(\mathbb{C})\) such that \(AA^\ast\) only has real, positive eigenvalues, there exists a vector \(\vec{v} \in \mathbb{C}^n\) such that \(A \vec{v}^* = \sigma \vec{v}\), where \(\sigma\) is a real, positive number.\\
    \emph{Proof.} Consider a vector \(\vec{x} \in \mathbb{C}^n\) that is an eigenvector of \(AA^\ast\) with corresponding eigenvalue \(\lambda\).
    There are two cases:
    \begin{itemize}
        \item[(a)] \(A\vec{x}^*\) and \(\vec{x}\) are linearly dependent.
        \item[(b)] \(A\vec{x}^*\) and \(\vec{x}\) are linearly independent.
    \end{itemize}
    In case (a), we must have that \(A\vec{x}^* = \mu \vec{x}\) for some \(\mu \in \mathbb{C}\), since they are linearly dependent.
    Then \(AA^\ast \vec{x} = A \mu^\ast \vec{x}^* = \abs{\mu}^2 \vec{x} \equiv \lambda \vec{x}\), which is positive by definition.\\
    In case (b), the vector \(\vec{y} = A\vec{x}^* + \mu \vec{x}\) is non-zero for any \(\mu \in \mathbb{C}\), since \(A\vec{x}^*\) and \(\vec{x}\) are linearly independent.
    Then we can choose \(\mu\) such that \(\abs{\mu}^2 = \lambda\) to get that \(A \vec{y}^* = A\pclosed{A^\ast \vec{x} + \mu^\ast \vec{x}^*} = \lambda\vec{x} + \mu^\ast A\vec{x^*} = \mu\mu^\ast \vec{x} + \mu^\ast A\vec{x}^* = \mu^\ast \pclosed{A \vec{x}^* + \mu \vec{x}} = \mu^\ast \vec{y}\).\\
    As such, we can always find a vector \(\tilde{\vec{v}} \in \mathbb{C}^n\) such that \(A \tilde{\vec{v}}^* = \mu \tilde{\vec{v}}\) for some \(\mu \in \mathbb{C}^n\).
    Furthermore, we can define a vector \(\vec{v} = \exp{i\theta} \tilde{\vec{v}}\) for a \(\theta \in \mathbb{R}\) to get \(A\vec{v}^* = A \pclosed{\exp{i\theta} \tilde{\vec{v}}}^\ast = \exp{-i\theta} A\tilde{\vec{v}}^* = \exp{-i\theta} \mu \tilde{\vec{v}} = \exp{-2i\theta} \mu \exp{i\theta} \tilde{\vec{v}} = \exp{-2i\theta} \mu \vec{v} \equiv \sigma \vec{v}\).
    This allows us to choose the phase of \(\sigma = \exp{-2i\theta} \mu\) to be such that \(\sigma\) is real and positive.
    \medskip

    \paragraph{Eigenvalues of \(AA^\ast\) for symmetric \(A\).}
    Given an \(N \by N\) complex matrix \(A\), the eigenvalues of \(AA^\ast\) are always real and non-negative.\\
    \emph{Proof}.
    Consider the eigenvectors \(\cclosed{\vec{x}_i}\) of \(A\) with corresponding eigenvalues \(\mu_i\).
    Since \(A\) is symmetric, these eigenvectors form a basis for \(\mathbb{C}^n\).
    As such, any vector \(\vec{v} \in \mathbb{C}^n\) can be written as \(\vec{v} = \sum_i a_i \vec{x}_i\) for some coefficients \(a_i \in \mathbb{C}\).
    The eigenvalues of \(AA^\ast\) are real and non-negative if and only if \(AA^\ast\) is positive semi-definite.
    To check this, we can look at
    \begin{align*}
        \vec{v}^T AA^\ast \vec{v}^\ast
        &= \pclosed{\sum_i A^T a_i \vec{x}_i}^T \pclosed{\sum_j A^\ast a_j^\ast \vec{x}_j^\ast}
        = \sum_{ij} a_i a_j^\ast \pclosed{A \vec{x}_i}^T \pclosed{A^\ast \vec{x}_j^\ast} \\
        &= \sum_{ij} a_i a_j^\ast \pclosed{\mu_i \vec{x}_i}^T \pclosed{\mu_j^\ast \vec{x}_j^\ast}
        = \sum_{ij} a_i a_j^\ast \mu_i \mu_j^\ast \pclosed{\vec{x}_i^\dagger \vec{x}_j}^\ast \\
        &= \sum_i \cclosed{\abs{a_i}^2 \abs{\mu_i}^2 \norm{x_i}^2 + 2\sum_{j>i} \Re{a_i a_j^\ast \mu_i \mu_j^\ast \pclosed{\vec{x}_i^\dagger \vec{x}_j}^\ast}}
        \geq 0,
    \end{align*}
    where we have used that \(A\) is symmetric in the second transition.
    Since any vector in \(\mathbb{C}^n\) can be written on the form of \(\vec{v}\), this means that \(AA^\ast\) must be positive semi-definite, and all its eigenvalues must be real and non-negative.
    This last part can easily be seen by considering an eigenvector \(\vec{y}\) of \(AA^\ast\) with corresponding eigenvalue \(\lambda\).
    Then
    \[0 \leq \vec{y}^\dagger AA^\ast \vec{y} = \vec{y}^\dagger \lambda \vec{y} = \lambda \norm{\vec{y}}^2,\]
    meaning \(\lambda \geq 0\).

    \[AA^\ast = AA^\dagger = (AA^\dagger)^\dagger\]
    \[\vec{x}^T A A^\ast \vec{x}^\ast = (A^T \vec{x})^T (A \vec{x})^\ast = (A \vec{x})^T (A \vec{x})^\ast = \mu \vec{x}^T \mu^\ast \vec{x}^\ast = \abs{\mu}^2 (\vec{x}^\dagger \vec{x})^\ast \geq 0\]
    \[\sum_i a_i^\ast \vec{x}_i^T A A^\ast \sum_j a_j \vec{x}_j^\ast = \sum_{ij} a_i^\ast a_j (A \vec{x}_i)^T (A\vec{x}_j)^\ast = \sum_{ij} a_i^\ast a_j \mu_i \mu_j^\ast (\vec{x}_i^\dagger \vec{x}_j)^\ast\]
    \[= \sum_i \abs{a_i}^2 \abs{\mu_i}^2 \norm{\vec{x}_i}^2 + 2\sum_{j>i} \Re{a_i^\ast a_j \mu_i \mu_j^\ast (\vec{x}_i^\dagger \vec{x}_j)^\ast}\]

    \[(V^\dagger A V^\ast)_{i0} = V^\ast_{ki} A_{kl} V^\ast_{l0} = V^\ast_{ki} \sigma V_{k0} = \sigma \delta_{i0}\]
    \[(V^\dagger A V^\ast)_{0i} = V^\ast_{k0} A_{kl} V^\ast_{li} = A_{lk} V^\ast_{k0} V^\ast_{li} = \sigma V_{l0} V_{li}^\ast = \sigma \delta_{0i}\]
    \[\vec{v}_i^\dagger A \vec{v}^* = \vec{v}_i^\dagger \sigma \vec{v} = \sigma \vec{v}_i^\dagger \vec{v} = \sigma \vec{e}_0\]
    \[\vec{v}^\dagger A \vec{v}_i = (A^T \vec{v}^\ast)^T \vec{v}_i = (A \vec{v}^\ast)^T \vec{v}_i = \sigma\vec{v}^\dagger \vec{v}_i = \sigma \vec{e}_0^T\]

    \[(V^\dagger A V^\ast)^T = V^\dagger A^T V^\ast = V^\dagger A V^\ast\]

    \printbibliography

\end{document}
